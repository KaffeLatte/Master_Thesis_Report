\relax 
\providecommand*{\memsetcounter}[2]{}
\catcode `"\active 
\@writefile{toc}{\changetocdepth  {2}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\select@language{swedish}
\@writefile{toc}{\select@language{swedish}}
\@writefile{lof}{\select@language{swedish}}
\@writefile{lot}{\select@language{swedish}}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{spotifyPress}
\citation{spotifyPress}
\citation{spotifyPress}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {1}Introduction}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Project Introduction}{1}}
\citation{featureEng}
\citation{Ek:2011wu}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Project Aim}{2}}
\citation{melville2002content}
\citation{breese1998empirical}
\citation{sarwar2001item}
\citation{su2009survey}
\citation{adomavicius2005toward}
\citation{sarwar2001item}
\citation{melville2002content}
\citation{hu2008collaborative}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {2}Background}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Collaborative Filtering}{5}}
\citation{hu2008collaborative}
\citation{sarwar2001item}
\citation{breese1998empirical}
\citation{hu2008collaborative}
\citation{sarwar2001item}
\citation{su2009survey}
\citation{beyer1999nearest}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Image illustrating the problem collaborative filtering intends to solve. The question marks are items that the specific user have not rated. Collaborative filtering intends to infer these ratings.}}{6}}
\newlabel{colFiltMatImg}{{\M@TitleReference {2.1}{Image illustrating the problem collaborative filtering intends to solve. The question marks are items that the specific user have not rated. Collaborative filtering intends to infer these ratings.}}{6}}
\citation{breese1998empirical}
\citation{sarwar2001item}
\newlabel{corFilt1}{{\M@TitleReference {2.1}{Collaborative Filtering}}{7}}
\citation{hu2008collaborative}
\citation{CJ}
\citation{herlocker2004evaluating}
\citation{melville2002content}
\citation{adomavicius2005toward}
\citation{adomavicius2005toward}
\citation{gunawardana2009unified}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Content Based Approaches}{8}}
\citation{musicGenome}
\citation{tzanetakis2002musical}
\citation{logan2000mel}
\citation{hamel2010learning}
\citation{pazzani2007content}
\citation{adomavicius2005toward}
\citation{gunawardana2009unified}
\citation{adomavicius2005toward}
\citation{melville2002content}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Hybrid Systems}{9}}
\citation{ragno2005inferring}
\citation{koller2009probabilistic}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Playlist Generation}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}Probabilistic Graphical Models for Playlist Generation}{10}}
\citation{ragno2005inferring}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Illustration of an undirected graph. Here transitions between nodes A and B can be made, transitions can also be made between nodes A and C. No direct transitions between nodes B and C can be made.}}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Illustration of a directed graph. Each edge corresponds to a one way transition. In this graph transitions can be made between nodes A and B both ways, transitions can be made one way from node A to node C but not from C to A. From node C transitions to node B can be made, but no transitions from node B to node A are possible.}}{11}}
\citation{spotifyPress}
\citation{platt2001learning}
\citation{mackay1998introduction}
\citation{rasmussen2004gaussian}
\citation{rasmussen2006gaussian}
\citation{platt2001learning}
\citation{platt2001learning}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}Gaussian Processes for Playlist Generation}{12}}
\citation{platt2001learning}
\citation{bengio2013representation}
\citation{mulaik1987brief}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {3}Representation Learning}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Representation Learning}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Principal Component Analysis}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Graphical illustration of PCA}}{18}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {4}Representing Playlists}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Assumptions}{19}}
\citation{bertin2011million}
\citation{rehbein2010there}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Data}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Exploratory Data Analysis}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Learning Playlist Characteristics}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Visualization of covariances in a sample playlist. Zero variance terms have been removed. As can be seen there are linear correlations between features in the playlist data for this particular playlist. The conclusion that can be drawn from this is that there are dependencies between features and that the presence of certain features is related to other features and vice versa. This information is an important factor for modeling the characteristics of the playlist. The symmetry along the diagonal of the figure is due to relationships between features being two way. As can be seen from the geometry in the figure, features that are related are grouped into squares along the diagonal of the image.}}{22}}
\newlabel{plistCorrs}{{\M@TitleReference {4.1}{Visualization of covariances in a sample playlist. Zero variance terms have been removed. As can be seen there are linear correlations between features in the playlist data for this particular playlist. The conclusion that can be drawn from this is that there are dependencies between features and that the presence of certain features is related to other features and vice versa. This information is an important factor for modeling the characteristics of the playlist. The symmetry along the diagonal of the figure is due to relationships between features being two way. As can be seen from the geometry in the figure, features that are related are grouped into squares along the diagonal of the image.}}{22}}
\citation{cortes1995support}
\citation{hsu2002comparison}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4.1}Handling zero variance terms}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Selecting candidate songs for a playlist}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5.1}Subspace method}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Illustration of how points relate to principal component spaces under projection of the subspace method.}}{25}}
\newlabel{subsIll}{{\M@TitleReference {4.2}{Illustration of how points relate to principal component spaces under projection of the subspace method.}}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Playlist Comparison}{26}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Hierarchical clustering of playlists where the aggregated measure of the weighted dot product matrix is taken by the sum of the matrix diagonal. If one looks closely at the diagonal it can be seen that this approach clusters playlists together, in the form of squares around the diagonal. Clusters are mostly in a pairwise manner and are sensible. For example \textit  {Dub on The Breach} and \textit  {Svensk Reggae} are clustered together, as are \textit  {House Workout} and \textit  {Dinner Party}, as well as \textit  {Coffee Table Jazz}, \textit  {Jazz p{\r a} Svenska} and \textit  {Late night Jazz}.}}{27}}
\newlabel{sum}{{\M@TitleReference {4.3}{Hierarchical clustering of playlists where the aggregated measure of the weighted dot product matrix is taken by the sum of the matrix diagonal. If one looks closely at the diagonal it can be seen that this approach clusters playlists together, in the form of squares around the diagonal. Clusters are mostly in a pairwise manner and are sensible. For example \textit  {Dub on The Breach} and \textit  {Svensk Reggae} are clustered together, as are \textit  {House Workout} and \textit  {Dinner Party}, as well as \textit  {Coffee Table Jazz}, \textit  {Jazz p{\r a} Svenska} and \textit  {Late night Jazz}.}}{27}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Hierarchical clustering of playlists where the aggregated measure of the weighted dot product matrix is taken by the absolute value of sum of the matrix diagonal. A look at the squares of correlation along the matrix diagonal shows interesting clusters. The three classical rock playlists in the data set are grouped together, three hip hop playlists are grouped into one cluster and so are three reggae playlists, there are two jazz clusters with two songs in each and there is also a workout/party cluster and a modern rock/metal cluster.}}{28}}
\newlabel{absSum}{{\M@TitleReference {4.4}{Hierarchical clustering of playlists where the aggregated measure of the weighted dot product matrix is taken by the absolute value of sum of the matrix diagonal. A look at the squares of correlation along the matrix diagonal shows interesting clusters. The three classical rock playlists in the data set are grouped together, three hip hop playlists are grouped into one cluster and so are three reggae playlists, there are two jazz clusters with two songs in each and there is also a workout/party cluster and a modern rock/metal cluster.}}{28}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Hierarchical clustering of playlists where the aggregated measure of the weighted dot product matrix is taken by the sum of the absolute values of the matrix diagonal. The clusters along the diagonal using this method are more prominent than using the other methods. The clusters are easier to spot along the diagonal of the picture. The playlist comparison method used for this figure also does not provide several smaller clusters that are similar, such as two jazz clusters or two hip hop clusters as in figure \ref  {sum} or figure \ref  {absSum}}}{29}}
\newlabel{absSumXXX}{{\M@TitleReference {4.5}{Hierarchical clustering of playlists where the aggregated measure of the weighted dot product matrix is taken by the sum of the absolute values of the matrix diagonal. The clusters along the diagonal using this method are more prominent than using the other methods. The clusters are easier to spot along the diagonal of the picture. The playlist comparison method used for this figure also does not provide several smaller clusters that are similar, such as two jazz clusters or two hip hop clusters as in figure \ref  {sum} or figure \ref  {absSum}}}{29}}
\citation{fix1951discriminatory}
\@writefile{toc}{\contentsline {section}{\numberline {4.7}Approximate Nearest Neighbours}{30}}
\citation{blum2006random}
\citation{andoni2006near}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces As can be seen the two data sets, if treated like independent data sets, have different location but still share the same principal components. This illustrates that information about location is thrown away by PCA. The information that is preserved is the direction, as the principal components show in which directions the variance in the data reside.}}{31}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Illustration of multiple subspace projections. The illustration shows how points can be separated by multiple projections. This is conceptually similar to locality sensitive hashing.}}{32}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {5}Results}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Precision}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Image showing the clustering used as a base for calculating precision. Clusters consisting of one single playlist were not used for evaluation.}}{36}}
\newlabel{sumAbsBetter}{{\M@TitleReference {5.1}{Image showing the clustering used as a base for calculating precision. Clusters consisting of one single playlist were not used for evaluation.}}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Images showing how the model, left image, performs compared to the baseline, right image, for precision at 10.}}{37}}
\newlabel{prec10}{{\M@TitleReference {5.2}{Images showing how the model, left image, performs compared to the baseline, right image, for precision at 10.}}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Comparing Model to Baseline}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Images showing how the model, left image, performs compared to the baseline, right image, for precision at 20.}}{38}}
\newlabel{prec20}{{\M@TitleReference {5.3}{Images showing how the model, left image, performs compared to the baseline, right image, for precision at 20.}}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Images showing how the model, left image, performs compared to the baseline, right image, for precision at 30.}}{38}}
\newlabel{prec30}{{\M@TitleReference {5.4}{Images showing how the model, left image, performs compared to the baseline, right image, for precision at 30.}}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Image showing the averages for the model including data points for precision at 10}}{39}}
\newlabel{ilUno}{{\M@TitleReference {5.5}{Image showing the averages for the model including data points for precision at 10}}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Image showing the averages for the model including data points for precision at 20}}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Image showing the averages for the model including data points for precision at 30}}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Image showing the averages for the model including data points for precision at 10 with one outlier removed}}{40}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Image showing the averages for the model including data points for precision at 20 with one outlier removed}}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Image showing the averages for the model including data points for precision at 30 with one outlier removed}}{41}}
\newlabel{ilLast}{{\M@TitleReference {5.10}{Image showing the averages for the model including data points for precision at 30 with one outlier removed}}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Confusions}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 1 tree in the pre-filtering step.}}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 3 trees in the pre-filtering step.}}{43}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 5 trees in the pre-filtering step.}}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 10 trees in the pre-filtering step.}}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 20 trees in the pre-filtering step.}}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 30 trees in the pre-filtering step.}}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Image to the left showing a histogram over similarity ranks to the seed playlists, for the playlists to which the false positive samples belong. The figure to the right shows the cumulative distribution of rankings. Both figures show performance for 50 trees in the pre-filtering step.}}{46}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Qualitative Evaluations}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Results from qualitative evaluation for Hip Hop. The image to the left shows the performance of how the tracks in the playlist for qualitative evaluation matches the playlist theme for both the model and the reference playlist. First column shows how well the tracks in the model playlist matches the theme, second column how well the tracks from the model matches the theme with outliers removed. The third and fourth column show the same values for the reference playlist. The image to the right shows the number of outliers found for the playlist from the model or reference respectively. As can be seen the model slightly outperforms the reference. The most probable reason for one person spotting eight outliers in the model is that the user saw one outlier and that was track number eight. Feedback after the qualitative evaluation confirms this.}}{47}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Results from qualitative evaluation for Rock. The image to the left shows the performance of how the tracks in the playlist for qualitative evaluation matches the playlist theme for both the model and the reference playlist. First column shows how well the tracks in the model playlist matches the theme, second column how well the tracks from the model matches the theme with outliers removed. The third and fourth column show the same values for the reference playlist. The image to the right shows the number of outliers found for the playlist from the model or reference respectively. As can be seen the model outperforms the reference. A reasonable explanation to the low performance of the reference could be that experts designing the playlist and the users evaluating the playlist have different opinions about what rock is. Is the song \textit  {Son of a preacher man} that was present among the reference songs old school rock or pop for example.}}{48}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Qualitative results for the Metal playlists. The image to the left shows the performance of how the tracks in the playlist for qualitative evaluation matches the playlist theme for both the model and the reference playlist. First column shows how well the tracks in the model playlist matches the theme, second column how well the tracks from the model matches the theme with outliers removed. The third and fourth column show the same values for the reference playlist. The image to the right shows the number of outliers found for the playlist from the model or reference respectively. As can be seen the reference clearly outperforms the model. As one user misunderstood the outlier scale for Hip Hop it is reasonable to assume that the one person ranking the number of outliers for the metal playlist having commited the same mistake, but as opinions about music differ we cannot be sure about this.}}{49}}
\@writefile{lof}{\addvspace {10pt}}
\@writefile{lot}{\addvspace {10pt}}
\@writefile{toc}{\contentsline {chapter}{\chapternumberline {6}Discussion and Future Work}{51}}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Discussion}{51}}
\citation{kwatra2010fast}
\citation{pan1999complexity}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Complexity Analysis}{52}}
\bibdata{refList}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Future Work}{54}}
\bibcite{adomavicius2005toward}{1}
\bibcite{andoni2006near}{2}
\bibcite{bengio2013representation}{3}
\bibcite{bertin2011million}{4}
\bibcite{beyer1999nearest}{5}
\bibcite{blum2006random}{6}
\bibcite{breese1998empirical}{7}
\bibcite{cortes1995support}{8}
\bibcite{Ek:2011wu}{9}
\bibcite{fix1951discriminatory}{10}
\@writefile{toc}{\contentsline {chapter}{Bibliography}{55}}
\bibcite{gunawardana2009unified}{11}
\bibcite{hamel2010learning}{12}
\bibcite{herlocker2004evaluating}{13}
\bibcite{hsu2002comparison}{14}
\bibcite{hu2008collaborative}{15}
\bibcite{CJ}{16}
\bibcite{koller2009probabilistic}{17}
\bibcite{kwatra2010fast}{18}
\bibcite{logan2000mel}{19}
\bibcite{mackay1998introduction}{20}
\bibcite{melville2002content}{21}
\bibcite{mulaik1987brief}{22}
\bibcite{featureEng}{23}
\bibcite{pan1999complexity}{24}
\bibcite{musicGenome}{25}
\bibcite{pazzani2007content}{26}
\bibcite{platt2001learning}{27}
\bibcite{ragno2005inferring}{28}
\bibcite{rasmussen2004gaussian}{29}
\bibcite{rasmussen2006gaussian}{30}
\bibcite{rehbein2010there}{31}
\bibcite{sarwar2001item}{32}
\bibcite{su2009survey}{33}
\bibcite{spotifyPress}{34}
\bibcite{tzanetakis2002musical}{35}
\bibstyle{plain}
\memsetcounter{lastsheet}{65}
\memsetcounter{lastpage}{57}
